{"cells":[{"cell_type":"markdown","metadata":{"id":"vEen_k3Xmwke"},"source":["<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"Uz8NZZ4Lmwkg"},"source":["# T81-558: Applications of Deep Neural Networks\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/index.html)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n","\n","**Module 10 Assignment: Time Series Neural Network**\n","\n","**Student Name: Your Name**"]},{"cell_type":"markdown","metadata":{"id":"jbwZ1KJLmwkh"},"source":["# Assignment Instructions\n","\n","For this assignment, you will use an LSTM to predict a time series contained in the data file **[series-31-num.csv](https://data.heatonresearch.com/data/t81-558/datasets/series-31-num.csv)**.  The code that you will use to complete this will be similar to the sunspots example from the course module.  This data set contains two columns: *time* and *value*.  Create an LSTM network and train it with a sequence size of 5 and a prediction window of 1.  If you use a different sequence size, you will not have the correct number of submission rows. Train the neural network, the data set is relatively simple, and you should easily be able to get an RMSE below 1.0.  FYI, I generate this dataset by fitting a cubic spline to a series of random points.\n","\n","This file contains a time series data set, do not randomize the order of the rows!  For your training data, use all *time* values less than 3000, and for the test, use the remaining amounts greater than or equal to 3000. For the submit file, please send me the results of your test evaluation.  You should have two columns: *time* and *value*.  The column *time* should be the time at the beginning of each predicted sequence. The *value* should be the next value that your neural network predicted for each of the sequences.\n","\n","Your submission file will look similar to:\n","\n","|time|value|\n","|-|-|\n","|3000|37.022846|\n","|3001|37.030582|\n","|3002|37.03816|\n","|3003|37.045563|\n","|3004|37.0528|\n","|...|...|"]},{"cell_type":"markdown","metadata":{"id":"RJ23Vnk2mwki"},"source":["# Google CoLab Instructions\n","\n","If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGJU28vsmwki","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731285212070,"user_tz":-480,"elapsed":23444,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"3557eaef-8278-4fdb-e5e4-0d75cd3747ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Note: using Google CoLab\n"]}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False"]},{"cell_type":"markdown","metadata":{"id":"L2chpDkmmwkk"},"source":["# Assignment Submit Function\n","\n","You will submit the ten programming assignments electronically.  The following **submit** function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any underlying problems.\n","\n","**It is unlikely that should need to modify this function.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xHo5-STGmwkk"},"outputs":[],"source":["import base64\n","import os\n","import numpy as np\n","import pandas as pd\n","import requests\n","import PIL\n","import PIL.Image\n","import io\n","\n","# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n","# submission counts.  The paramaters are as follows:\n","# data - List of pandas dataframes or images.\n","# key - Your student key that was emailed to you.\n","# course - The course that you are in, currently t81-558 or t81-559.\n","# no - The assignment class number, should be 1 through 1.\n","# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n","# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n","def submit(data,key,course,no,source_file=None):\n","    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n","    if source_file is None: source_file = __file__\n","    suffix = '_class{}'.format(no)\n","    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n","    with open(source_file, \"rb\") as image_file:\n","        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n","    ext = os.path.splitext(source_file)[-1].lower()\n","    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n","    payload = []\n","    for item in data:\n","        if type(item) is PIL.Image.Image:\n","            buffered = BytesIO()\n","            item.save(buffered, format=\"PNG\")\n","            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n","        elif type(item) is pd.core.frame.DataFrame:\n","            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n","    r= requests.post(\"https://api.heatonresearch.com/wu/submit\",\n","        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'course':course, 'ext':ext, 'py':encoded_python})\n","    if r.status_code==200:\n","        print(\"Success: {}\".format(r.text))\n","    else: print(\"Failure: {}\".format(r.text))"]},{"cell_type":"markdown","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"-41cE24Umwkl"},"source":["# Assignment #10 Sample Code\n","\n","The following code provides a starting point for this assignment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqKnJZ5Fmwkl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731285627724,"user_tz":-480,"elapsed":577,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"af977cd1-e76d-455c-fb14-ef49bb59de42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting file:\n","   time      value\n","0     0  10.000000\n","1     1  10.050953\n","2     2  10.101758\n","3     3  10.152415\n","4     4  10.202924\n","5     5  10.253286\n","6     6  10.303499\n","7     7  10.353566\n","8     8  10.403485\n","9     9  10.453256\n","Ending file:\n","      time      value\n","3990  3990  14.694572\n","3991  3991  14.727313\n","3992  3992  14.760351\n","3993  3993  14.793687\n","3994  3994  14.827322\n","3995  3995  14.861256\n","3996  3996  14.895491\n","3997  3997  14.930026\n","3998  3998  14.964862\n","3999  3999  15.000000\n","Training set has 3000 observations.\n","Test set has 1000 observations.\n","Shape of training set: (2995, 5, 1)\n","Shape of test set: (995, 5, 1)\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","def to_sequences(seq_size, obs):\n","    x = []\n","    y = []\n","\n","    for i in range(len(obs)-SEQUENCE_SIZE):\n","        #print(i)\n","        window = obs[i:(i+SEQUENCE_SIZE)]\n","        after_window = obs[i+SEQUENCE_SIZE]\n","        window = [[x] for x in window]\n","        #print(\"{} - {}\".format(window,after_window))\n","        x.append(window)\n","        y.append(after_window)\n","\n","    return np.array(x),np.array(y)\n","\n","\n","# This is your student key that I emailed to you at the beginnning of the semester.\n","# key = \"H3B554uPhc3f8kirGGBYA7cYuDOamhXM87OY6QH1\"  # This is an example key and will not work.\n","key = \"\"\n","\n","# You must also identify your source file.  (modify for your local setup)\n","# file='/resources/t81_558_deep_learning/assignment_yourname_class1.ipynb'  # IBM Data Science Workbench\n","#file='C:\\\\users\\\\jeff\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class10.ipynb'  # Windows\n","#file='/Users/jeff/projects/t81_558_deep_learning/assignments/assignment_yourname_class10.ipynb'  # Mac/Linux\n","\n","file= '/content/drive/My Drive/Colab Notebooks/assignment_ZhijiangLi_class10.ipynb'\n","\n","\n","# Read from time series file\n","df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/series-31-num.csv\")\n","\n","\n","\n","print(\"Starting file:\")\n","print(df[0:10])\n","\n","print(\"Ending file:\")\n","print(df[-10:])\n","\n","df_train = df[df['time']<3000]\n","df_test = df[df['time']>=3000]\n","\n","spots_train = df_train['value'].tolist()\n","spots_test = df_test['value'].tolist()\n","\n","print(\"Training set has {} observations.\".format(len(spots_train)))\n","print(\"Test set has {} observations.\".format(len(spots_test)))\n","\n","SEQUENCE_SIZE = 5\n","x_train,y_train = to_sequences(SEQUENCE_SIZE,spots_train)\n","x_test,y_test = to_sequences(SEQUENCE_SIZE,spots_test)\n","\n","print(\"Shape of training set: {}\".format(x_train.shape))\n","print(\"Shape of test set: {}\".format(x_test.shape))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5opEJnLdmwkm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731286003125,"user_tz":-480,"elapsed":56527,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"33abbfbb-9ed6-4850-91bb-b55659bcfd7f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Success: Submitted Assignment 10 (t81-558) for l.zhijiang:\n","You have submitted this assignment 5 times. (this is fine)\n","Note: The mean difference 0.41556561681229454 for column 'value' is acceptable and is less than the maximum allowed value of '1.0' for this assignment.\n","No warnings or errors (only notes), you will probably do well, but no guarantee. :-)\n"]}],"source":["# continue here\n","\n","sequence_size = 5\n","x_train, y_train = to_sequences(sequence_size, spots_train)\n","x_test, y_test = to_sequences(sequence_size, spots_test)\n","\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","x_train = scaler.fit_transform(x_train.reshape(-1, 1)).reshape(x_train.shape)\n","y_train = scaler.transform(y_train.reshape(-1, 1))\n","x_test = scaler.transform(x_test.reshape(-1, 1)).reshape(x_test.shape)\n","y_test = scaler.transform(y_test.reshape(-1, 1))\n","\n","x_train = torch.tensor(x_train, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.float32)\n","x_test = torch.tensor(x_test, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.float32)\n","\n","train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=64, shuffle=False)\n","\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size=1, hidden_size=64, num_layers=2):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, x):\n","        h_0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n","        c_0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n","        out, _ = self.lstm(x, (h_0, c_0))\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","model = LSTMModel()\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n","\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    for x_batch, y_batch in train_loader:\n","        optimizer.zero_grad()\n","        output = model(x_batch)\n","        loss = criterion(output, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","    scheduler.step(loss)\n","    # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n","\n","model.eval()\n","predictions = []\n","\n","with torch.no_grad():\n","    for x in x_test:\n","        predictions.append(model(x.unsqueeze(0)).item())\n","\n","predicted_values = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n","\n","df = pd.DataFrame({\n","    'time': df_test['time'].values[:len(predicted_values)],  # Use test set times directly\n","    'value': predicted_values.flatten()\n","})\n","\n","submit_df = df\n","# submit_df\n","submit(source_file=file,data=[submit_df],key=key,course='t81-558',no=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5Hcu0gGmwkm"},"outputs":[],"source":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3.11 (genai)","language":"python","name":"pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"colab":{"provenance":[{"file_id":"https://github.com/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class10.ipynb","timestamp":1731284641984}]}},"nbformat":4,"nbformat_minor":0}