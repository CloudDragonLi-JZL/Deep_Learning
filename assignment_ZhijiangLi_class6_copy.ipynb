{"cells":[{"cell_type":"markdown","metadata":{"id":"CdL1ZvDepO-X"},"source":["<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"R_pemiL8pO-Y"},"source":["# T81-558: Applications of Deep Neural Networks\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/index.html)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n","\n","**Module 6 Assignment: Extract Text with LLM**\n","\n","**Student Name: Your Name**"]},{"cell_type":"markdown","metadata":{"id":"lky4xopspO-Z"},"source":["# Assignment Instructions\n","\n","A [file](https://s3.amazonaws.com/data.heatonresearch.com/data/t81-558/sentences.csv) is provided that contains 100 English sentences. Sample sentences from this file include:\n","\n","|id|sentence|\n","|---|---|\n","|1|Sarah found an old photograph in the attic.|\n","|2|By the window, Jake noticed a sparkling diamond necklace.|\n","|3|The antique clock was expertly fixed by Robert.|\n","|4|At the beach, Maria stumbled upon a washed-up bottle.|\n","|...|...|\n","\n","For each of these sentences you should extract the name of the person from the sentence. The results of this assignment would look like the following for the above input.\n","\n","|id|name|\n","|---|---|\n","|1|Sarah|\n","|2|Jake|\n","|3|Robert|\n","|4|Maria|\n","|...|...|\n","\n","Use a large language model (LLM) to extract the single word action from each of these sentences.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U4LQZW_SpO-Z"},"source":["# Google CoLab Instructions\n","\n","If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZnCEIEopO-Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728969843641,"user_tz":-480,"elapsed":7206,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"11984d74-fc2b-4ffb-f4f4-eeda655f8740"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Note: using Google CoLab\n"]}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False"]},{"cell_type":"markdown","metadata":{"id":"vwx0hsWE3CQd"},"source":["# LangChain Setup\n","\n","We must first install LangChain, refer to Module 6.2 for more information."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRPrqvDn3jYh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728969851221,"user_tz":-480,"elapsed":4937,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"4cd637bd-f95c-49e6-bb77-2aad79bb93ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.3)\n","Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.2)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.10)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.135)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n","Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.51.2)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.8.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.14.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.6.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain) (3.0.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n"]}],"source":["!pip install langchain langchain_openai"]},{"cell_type":"markdown","metadata":{"id":"-A83r4MU3kmk"},"source":["You will need a key for this assignment, for WUSTL students, look at Assignment 6 in Canvas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPutwNcc3mwj"},"outputs":[],"source":["from langchain_openai import OpenAI, ChatOpenAI\n","\n","# Your OpenAI API key\n","# If you are in my class at WUSTL, get this key from the Assignment 6 description in Canvas.\n","OPENAI_KEY = ''\n","\n","# This is the model you will generally use for this class\n","LLM_MODEL = 'gpt-3.5-turbo-instruct'\n","\n","# Initialize the OpenAI LLM (Language Learning Model) with your API key\n","llm = OpenAI(openai_api_key=OPENAI_KEY, model=LLM_MODEL, temperature=0)"]},{"cell_type":"markdown","metadata":{"id":"PMLHwV0hpO-a"},"source":["# Assignment Submit Function\n","\n","You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems.\n","\n","**It is unlikely that should need to modify this function.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozSyLCNtpO-a"},"outputs":[],"source":["import base64\n","import os\n","import numpy as np\n","import pandas as pd\n","import requests\n","import PIL\n","import PIL.Image\n","import io\n","\n","# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n","# submission counts.  The paramaters are as follows:\n","# data - List of pandas dataframes or images.\n","# key - Your student key that was emailed to you.\n","# course - The course that you are in, currently t81-558 or t81-559.\n","# no - The assignment class number, should be 1 through 1.\n","# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n","# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n","def submit(data,key,course,no,source_file=None):\n","    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n","    if source_file is None: source_file = __file__\n","    suffix = '_class{}'.format(no)\n","    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n","    with open(source_file, \"rb\") as image_file:\n","        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n","    ext = os.path.splitext(source_file)[-1].lower()\n","    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n","    payload = []\n","    for item in data:\n","        if type(item) is PIL.Image.Image:\n","            buffered = BytesIO()\n","            item.save(buffered, format=\"PNG\")\n","            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n","        elif type(item) is pd.core.frame.DataFrame:\n","            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n","    r= requests.post(\"https://api.heatonresearch.com/wu/submit\",\n","        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'course':course, 'ext':ext, 'py':encoded_python})\n","    if r.status_code==200:\n","        print(\"Success: {}\".format(r.text))\n","    else: print(\"Failure: {}\".format(r.text))"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"H7kgvLHspO-a","jupyter":{"outputs_hidden":true}},"source":["# Assignment #6 Sample Code\n","\n","The following code provides a starting point for this assignment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZPLGWgkpO-a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728971787634,"user_tz":-480,"elapsed":60441,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"285f2bf6-4f4d-4bc1-c9db-bd7bb21e817b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Success: Submitted Assignment 6 (t81-558) for l.zhijiang:\n","You have submitted this assignment 3 times. (this is fine)\n","No errors, warnings, or notes on your data. Rock on! You will probably do well, but no guarantee. :-)\n"]}],"source":["import os\n","import pandas as pd\n","from scipy.stats import zscore\n","import string\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.chains import LLMChain\n","\n","# This is your student key that I emailed to you at the beginnning of the semester.\n","# key = \"uTtH5yNbPs9tZdRWsBf9V9FaQA9RU2iP5cL7F3zH\" #\"Gx5en9cEVvaZnjut6vfLm1HG4ZO4PsI32sgldAXj\"  # This is an example key and will not work.\n","\n","key = \"\"\n","\n","# You must also identify your source file.  (modify for your local setup)\n","# file='/content/drive/My Drive/Colab Notebooks/assignment_yourname_class6.ipynb'  # Google CoLab\n","# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class6.ipynb'  # Windows\n","# file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class6.ipynb'  # Mac/Linux\n","\n","file= '/content/drive/My Drive/Colab Notebooks/assignment_ZhijiangLi_class6.ipynb'\n","\n","# Begin assignment\n","\n","df = pd.read_csv(\"https://s3.amazonaws.com/data.heatonresearch.com/data/t81-558/sentences.csv\",na_values=['?'])\n","\n","\n","template = ChatPromptTemplate.from_template(\"Extract the person name from this sentence: '{sentence}'.\")\n","\n","\n","inputs = [{'sentence': s} for s in df['sentence']]\n","\n","\n","chain = LLMChain(llm=llm, prompt=template)\n","\n","\n","result = [chain.run(input_data) for input_data in inputs]\n","\n","df['name'] = result\n","\n","df['name'] = df['name'].str.replace(r'\\n+', '', regex=True)\n","\n","df_submit = df[['id','name']]\n","\n","# df_submit\n","\n","# Submit\n","submit(source_file=file,data=[df_submit],key=key,course='t81-558',no=6)"]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[{"file_id":"https://github.com/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class6.ipynb","timestamp":1728964836698}]},"kernelspec":{"display_name":"Python 3.11 (genai)","language":"python","name":"pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}