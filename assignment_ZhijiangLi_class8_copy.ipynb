{"cells":[{"cell_type":"markdown","metadata":{"id":"domrnonINuu4"},"source":["<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"hTAVwaaOFuEf"},"source":["# T81-558: Applications of Deep Neural Networks\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/academics/programs/index.html)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n","\n","**Module 8 Assignment: Feature Engineering**\n","\n","**Student Name: Your Name**"]},{"cell_type":"markdown","metadata":{"id":"4YUdI4CcFuEg"},"source":["# Assignment Instructions\n","\n","This assignment is similar to assignment 5, except that you must use feature engineering to solve it.  I provide you with a dataset that contains dimensions and the quality of items of specific shapes.  With the values of 'height', 'width', 'depth'. 'shape', and 'quality' you should try to predict the cost of these items.  You should be able to match very close to solution file, if you feature engineer correctly.  To get full credit your average cost should not be more than 50 off from the solution.  The autocorrector will let you know if you are in this range.\n","\n","You can find all of the needed CSV files here:\n","\n","* [Shapes - Training](https://data.heatonresearch.com/data/t81-558/datasets/shapes-train.csv)\n","* [Shapes - Submit](https://data.heatonresearch.com/data/t81-558/datasets/shapes-test.csv)\n","\n","Use the training file to train your neural network and submit results for for the data contained in the test/submit file."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZvFFOR5A-Wo","outputId":"3c0da8da-6ade-44d6-b36d-58f659137bca","executionInfo":{"status":"ok","timestamp":1730273776850,"user_tz":-480,"elapsed":2659,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Note: using Google CoLab\n"]}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False"]},{"cell_type":"markdown","metadata":{"id":"4qrsT_KZFuEh"},"source":["# Assignment Submit Function\n","\n","You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems.\n","\n","**It is unlikely that should need to modify this function.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43KOAL0OFuEi"},"outputs":[],"source":["import base64\n","import os\n","import numpy as np\n","import pandas as pd\n","import requests\n","import PIL\n","import PIL.Image\n","import io\n","\n","# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n","# submission counts.  The paramaters are as follows:\n","# data - List of pandas dataframes or images.\n","# key - Your student key that was emailed to you.\n","# course - The course that you are in, currently t81-558 or t81-559.\n","# no - The assignment class number, should be 1 through 1.\n","# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n","# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n","def submit(data,key,course,no,source_file=None):\n","    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n","    if source_file is None: source_file = __file__\n","    suffix = '_class{}'.format(no)\n","    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n","    with open(source_file, \"rb\") as image_file:\n","        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n","    ext = os.path.splitext(source_file)[-1].lower()\n","    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n","    payload = []\n","    for item in data:\n","        if type(item) is PIL.Image.Image:\n","            buffered = BytesIO()\n","            item.save(buffered, format=\"PNG\")\n","            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n","        elif type(item) is pd.core.frame.DataFrame:\n","            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n","    r= requests.post(\"https://api.heatonresearch.com/wu/submit\",\n","        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'course':course, 'ext':ext, 'py':encoded_python})\n","    if r.status_code==200:\n","        print(\"Success: {}\".format(r.text))\n","    else: print(\"Failure: {}\".format(r.text))"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"zd5fX98YFuEm","jupyter":{"outputs_hidden":true}},"source":["# Assignment #8 Sample Code\n","\n","The following code provides a starting point for this assignment."]},{"cell_type":"code","source":["!pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edyLjsQuSD36","executionInfo":{"status":"ok","timestamp":1730273786375,"user_tz":-480,"elapsed":4943,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"113c5d98-bbd4-4d51-aa0f-6c0ed537431f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lIB3MmKuFuEn","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730276966409,"user_tz":-480,"elapsed":3024,"user":{"displayName":"zhijiang li","userId":"10140336851914014055"}},"outputId":"034d8699-4683-415c-be19-546978afcdc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Success: Submitted Assignment 8 (t81-558) for l.zhijiang:\n","You have submitted this assignment 28 times. (this is fine)\n","Note: The mean difference 1.1142096244070672 for column 'cost' is acceptable and is less than the maximum allowed value of '50.0' for this assignment.\n","No warnings or errors (only notes), you will probably do well, but no guarantee. :-)\n"]}],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.ensemble import GradientBoostingRegressor\n","\n","# This is your student key that I emailed to you at the beginnning of the semester.\n","# key = \"Gx5en9cEVvcsjuijujijisdsdZO4PsI32sgldAXj\"  # This is an example key and will not work.\n","\n","key = \"\"\n","\n","# You must also identify your source file.  (modify for your local setup)\n","# file='/content/drive/My Drive/Colab Notebooks/assignment_solution_class8.ipynb'  # Google CoLab\n","# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class8.ipynb'  # Windows\n","# file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class8.ipynb'  # Mac/Linux\n","\n","file= '/content/drive/My Drive/Colab Notebooks/assignment_ZhijiangLi_class8.ipynb'\n","\n","# Begin assignment\n","df_train = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/shapes-train.csv\")\n","df_submit = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/shapes-test.csv\")\n","\n","###\n","# def calculate_volume(row):\n","#     if row['shape'] == 'box':\n","#         return row['height'] * row['width'] * row['depth']\n","#     elif row['shape'] == 'cylinder':\n","#         return np.pi * (row['width'] / 2) ** 2 * row['height']\n","#     elif row['shape'] == 'ellipsoid':\n","#         return (4/3) * np.pi * (row['height'] / 2) * (row['width'] / 2) * (row['depth'] / 2)\n","#     return 0\n","\n","# df_train['volume'] = df_train.apply(calculate_volume, axis=1)\n","# df_submit['volume'] = df_submit.apply(calculate_volume, axis=1)\n","\n","# X = df_train[['height', 'width', 'depth', 'shape', 'quality', 'volume']]\n","# y = df_train['cost']\n","\n","# preprocessor = ColumnTransformer(\n","#     transformers=[\n","#         ('shape', OneHotEncoder(), ['shape']),\n","#         ('scaler', StandardScaler(), ['height', 'width', 'depth', 'quality', 'volume'])\n","#     ])\n","\n","\n","# ## X = preprocessor.fit_transform(X) ## 1\n","# pipeline = Pipeline([\n","#     ('preprocessor', preprocessor),\n","#     ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n","#     ('regressor', GradientBoostingRegressor(n_estimators=200, max_depth=6, random_state=42))\n","# ])\n","\n","\n","# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# pipeline.fit(X_train, y_train)\n","\n","# # Evaluate on validation set\n","# y_pred = pipeline.predict(X_val)\n","# mae = mean_absolute_error(y_val, y_pred)\n","\n","# X_submit = df_submit[['height', 'width', 'depth', 'shape', 'quality', 'volume']]\n","# X_submit_transformed = pipeline.predict(X_submit)\n","\n","# df_submit = pd.DataFrame({\n","#     'cost': X_submit_transformed.flatten(),  # Match 'cost' header\n","#     'id': df_submit['id']\n","# })\n","###\n","\n","###\n","# X_train_tensor = torch.tensor(X_train.astype(np.float32))\n","# X_val_tensor = torch.tensor(X_val.astype(np.float32))\n","# y_train_tensor = torch.tensor(y_train.values.astype(np.float32)).view(-1, 1)\n","# y_val_tensor = torch.tensor(y_val.values.astype(np.float32)).view(-1, 1)\n","\n","\n","# class CostPredictorNN(nn.Module):\n","#     def __init__(self):\n","#         super(CostPredictorNN, self).__init__()\n","#         self.fc1 = nn.Linear(X_train.shape[1], 64)\n","#         self.fc2 = nn.Linear(64, 32)\n","#         self.fc3 = nn.Linear(32, 1)\n","#         self.relu = nn.ReLU()\n","\n","#     def forward(self, x):\n","#         x = self.relu(self.fc1(x))\n","#         x = self.relu(self.fc2(x))\n","#         x = self.fc3(x)\n","#         return x\n","\n","\n","# model = CostPredictorNN()\n","# criterion = nn.MSELoss()\n","# optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","# epochs = 100\n","# for epoch in range(epochs):\n","#     model.train()\n","#     optimizer.zero_grad()\n","#     output = model(X_train_tensor)\n","#     loss = criterion(output, y_train_tensor)\n","#     loss.backward()\n","#     optimizer.step()\n","\n","#     if (epoch+1) % 10 == 0:\n","#         model.eval()\n","#         val_output = model(X_val_tensor)\n","#         val_loss = criterion(val_output, y_val_tensor)\n","#         # print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n","\n","\n","# model.eval()\n","# val_predictions = model(X_val_tensor).detach().numpy()\n","# mae = mean_absolute_error(y_val, val_predictions)\n","# # print(\"Mean Absolute Error on Validation Set:\", mae)\n","\n","# X_submit = preprocessor.transform(df_submit[['height', 'width', 'depth', 'shape', 'quality', 'volume']])\n","# X_submit_tensor = torch.tensor(X_submit.astype(np.float32))\n","# # submit_predictions = model(X_submit_tensor).detach().numpy() ## 1\n","\n","# df_submit = pd.DataFrame({'cost': submit_predictions.flatten(), 'id': df_submit['id']})\n","# df_submit\n","###\n","\n","def calculate_volume(row):\n","    if row['shape'] == 'box':\n","        return row['height'] * row['width'] * row['depth']\n","    elif row['shape'] == 'cylinder':\n","        return np.pi * (row['width'] / 2) ** 2 * row['height']\n","    elif row['shape'] == 'ellipsoid':\n","        return (4/3) * np.pi * (row['height'] / 2) * (row['width'] / 2) * (row['depth'] / 2)\n","    return 0\n","\n","df_train['volume'] = df_train.apply(calculate_volume, axis=1)\n","df_submit['volume'] = df_submit.apply(calculate_volume, axis=1)\n","\n","X = df_train[['height', 'width', 'depth', 'shape', 'quality', 'volume']]\n","y = df_train['cost']\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('shape', OneHotEncoder(), ['shape']),\n","        ('scaler', StandardScaler(), ['height', 'width', 'depth', 'quality', 'volume'])\n","    ])\n","\n","#\n","gb_pipeline = Pipeline([\n","    ('preprocessor', preprocessor),\n","    # ('poly', PolynomialFeatures(degree=2, include_bias=False)),# no this even better\n","    ('regressor', GradientBoostingRegressor(n_estimators=40, max_depth=6, random_state=42))\n","    # 200, 6\n","])\n","\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","## testing\n","gb_pipeline.fit(X_train, y_train)\n","y_pred_gb = gb_pipeline.predict(X_val)\n","\n","mae_gb = mean_absolute_error(y_val, y_pred_gb)\n","# print(\"Gradient Boosting MAE on Validation Set:\", mae_gb)\n","\n","# Model\n","class CostPredictorNN(nn.Module):\n","    def __init__(self, input_size):\n","        super(CostPredictorNN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 64)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, 1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","X_train_tensor = torch.tensor(preprocessor.fit_transform(X_train).astype(np.float32))\n","X_val_tensor = torch.tensor(preprocessor.transform(X_val).astype(np.float32))\n","y_train_tensor = torch.tensor(y_train.values.astype(np.float32)).view(-1, 1)\n","y_val_tensor = torch.tensor(y_val.values.astype(np.float32)).view(-1, 1)\n","\n","nn_model = CostPredictorNN(X_train_tensor.shape[1])\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(nn_model.parameters(), lr=0.001)\n","\n","# Train\n","epochs = 100\n","for epoch in range(epochs):\n","    nn_model.train()\n","    optimizer.zero_grad()\n","    output = nn_model(X_train_tensor)\n","    loss = criterion(output, y_train_tensor)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch+1) % 10 == 0:\n","        nn_model.eval()\n","        val_output = nn_model(X_val_tensor)\n","        val_loss = criterion(val_output, y_val_tensor)\n","        # print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n","\n","nn_model.eval()\n","val_predictions_nn = nn_model(X_val_tensor).detach().numpy()\n","mae_nn = mean_absolute_error(y_val, val_predictions_nn)\n","# print(\"MAE on Validation Set:\", mae_nn)\n","\n","X_submit = df_submit[['height', 'width', 'depth', 'shape', 'quality', 'volume']]\n","\n","if mae_gb < mae_nn:\n","    X_submit_transformed = gb_pipeline.predict(X_submit)\n","else:\n","    X_submit_tensor = torch.tensor(preprocessor.transform(X_submit).astype(np.float32))\n","    X_submit_transformed = nn_model(X_submit_tensor).detach().numpy().flatten()\n","\n","\n","\n","\n","df_submit = pd.DataFrame({\n","    'cost': X_submit_transformed.flatten(),\n","    'id': df_submit['id']\n","})\n","\n","\n","#\n","submit(source_file=file,data=[df_submit],key=key,course='t81-558',no=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4G6N5CthrsOH"},"outputs":[],"source":[]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[{"file_id":"https://github.com/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class8.ipynb","timestamp":1730262603313}]},"kernelspec":{"display_name":"Python 3.11 (genai)","language":"python","name":"pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}